{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: 3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "cv2 version: 3.3.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "from darkflow.net.build import TFNet\n",
    "print('python version:', sys.version)\n",
    "print('cv2 version:', cv2.__version__)\n",
    "## tensorflow-gpu \n",
    "## CUDA 7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ckeck tensorflow gpu\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "\n",
    "# ---\n",
    "# What returns in cmd\n",
    "# reference: https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell\n",
    "# 2017-11-02 23:23:21.039622: I tensorflow/core/common_runtime/direct_session.cc:300] Device mapping:\n",
    "# /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce 920M, pci bus id: 0000:04:00.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Object Detection with Darkflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_json(dicto, json_file_name='test.json'):\n",
    "    if not os.path.exists('./demo_folder/obj_info'):\n",
    "        os.makedirs('./demo_folder/obj_info/')\n",
    "    file_path = ('./demo_folder/obj_info/'+ json_file_name)\n",
    "    print(file_path)\n",
    "    js = json.dumps(dicto)\n",
    "    # Open new json file if not exist it will create\n",
    "    fp = open(file_path, 'w')\n",
    "    # write to json file\n",
    "    fp.write(js)\n",
    "    # close the connection\n",
    "    fp.close()\n",
    "\n",
    "\n",
    "def VOD_darkflow(video_path, video_fps, tf_threshold=0.3, tf_gpu=0.9, output_name='VOD_result.avi'):\n",
    "    \n",
    "    # Set TFNet initiail options\n",
    "    options = {\"model\": \"cfg/yolo.cfg\",\n",
    "               \"load\": \"bin/yolo.weights\",\n",
    "               \"threshold\": tf_threshold,\n",
    "               \"gpu\": tf_gpu}    \n",
    "    tfnet = TFNet(options)\n",
    "        \n",
    "    # Record use\n",
    "    total_time = 0            # Caculate total time-cost\n",
    "    total_tag_list = []       # Store detected object tags\n",
    "    total_info = {}           # Store detected information frame-by-frame\n",
    "    high_tag_dict = {}        # Store detected object tag with high confidence\n",
    "    mid_tag_dict = {}         # Store detected object tag with mid confidence\n",
    "    low_tag_dict = {}         # Store detected object tag with low confidence\n",
    "    i = 0                     # Get frame-count use \n",
    "    \n",
    "    # Check folder for saving data\n",
    "    if not os.path.exists('./demo_folder/obj_images/objImg_high'):\n",
    "        os.makedirs('./demo_folder/obj_images/objImg_high')\n",
    "    if not os.path.exists('./demo_folder/obj_images/objImg_mid'):\n",
    "        os.makedirs('./demo_folder/obj_images/objImg_mid')\n",
    "    if not os.path.exists('./demo_folder/obj_images/objImg_low'):\n",
    "        os.makedirs('./demo_folder/obj_images/objImg_low')\n",
    "    if not os.path.exists('./demo_folder/obj_info'):\n",
    "        os.makedirs('./demo_folder/obj_info/') \n",
    "\n",
    "    # Capture Video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if video_path == 0:\n",
    "        output_name = 'camVideo.avi'\n",
    "        video_w = 800\n",
    "        video_h = 600\n",
    "    else:\n",
    "        video_w = int(cap.get(3)) # float\n",
    "        video_h = int(cap.get(4)) # float\n",
    "        \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(('./demo_folder/'+output_name), fourcc, video_fps, (video_w, video_h))\n",
    "\n",
    "    while(True):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check time \n",
    "        e1 = cv2.getTickCount()\n",
    "\n",
    "        if ret:\n",
    "            # Initial dict for each frame\n",
    "            total_info[i] = []\n",
    "\n",
    "            # Prediction with tfnet \n",
    "            print('=== Start Predicting with darkflow ===')\n",
    "            predictions = tfnet.return_predict(frame)\n",
    "            if predictions:\n",
    "                for item in predictions:\n",
    "                    # Prediction information \n",
    "                    top_left_x = item['topleft']['x']\n",
    "                    top_left_y = item['topleft']['y']\n",
    "                    bot_right_x = item['bottomright']['x']\n",
    "                    bot_right_y = item['bottomright']['y']\n",
    "                    label = item['label']\n",
    "                    confidence = item['confidence']\n",
    "                    \n",
    "                    # Create rectangle for detected object information and place\n",
    "                    cv2.rectangle(frame, (top_left_x, top_left_y), (bot_right_x, bot_right_y), (0,255,0), 3)\n",
    "                    cv2.putText(frame, label, (bot_right_x-150, bot_right_y-60), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2, cv2.LINE_AA)\n",
    "                    cv2.putText(frame, str(round(confidence, 3)),(bot_right_x-150,bot_right_y-20), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 1,(80,50,255),2,cv2.LINE_AA)\n",
    "                    \n",
    "                    # Detected object image \n",
    "                    detected_obj = frame[top_left_y:bot_right_y, top_left_x:bot_right_x] #[height1:height2, width1:width2]\n",
    "\n",
    "                    # Store total_frames detection information\n",
    "                    total_info[i].append((label, str(round(confidence, 3))))\n",
    "                    \n",
    "                    # Store all detected tags \n",
    "                    if label not in total_tag_list:\n",
    "                        total_tag_list.append(label)\n",
    "\n",
    "                    # Store the first high-confidence object's img\n",
    "                    if confidence > 0.7:\n",
    "                        if label not in list(high_tag_dict.keys()):\n",
    "                            high_tag_dict[label] = (str(round(confidence, 2))+'_'+str(i))\n",
    "                            cv2.imwrite('./demo_folder/obj_images/objImg_high/{0}_{1}.png'.format(label, (str(round(confidence, 2))+'_'+str(i))), detected_obj)\n",
    "\n",
    "                    # Store the first mid-confidence object's img\n",
    "                    elif confidence > 0.4:\n",
    "                        if label not in list(mid_tag_dict.keys()):\n",
    "                            mid_tag_dict[label] = (str(round(confidence, 2))+'_'+str(i))\n",
    "                            cv2.imwrite('./demo_folder/obj_images/objImg_mid/{0}_{1}.png'.format(label, (str(round(confidence, 2))+'_'+str(i))), detected_obj)\n",
    "\n",
    "                    # Store the first low-confidence object's img\n",
    "                    else:\n",
    "                        if label not in list(low_tag_dict.keys()):\n",
    "                            low_tag_dict[label] = (str(round(confidence, 2))+'_'+str(i))\n",
    "                            cv2.imwrite('./demo_folder/obj_images/objImg_low/{0}_{1}.png'.format(label, (str(round(confidence, 2))+'_'+str(i))), detected_obj)\n",
    "                            \n",
    "        else:\n",
    "            break\n",
    "        # Display the resulting frame\n",
    "        cv2.imshow('frame',frame)\n",
    "\n",
    "        # write the frame to the output\n",
    "        if video_path == 0:\n",
    "            frame = cv2.resize(frame,(video_w, video_h), interpolation = cv2.INTER_CUBIC)\n",
    "        out.write(frame)\n",
    "\n",
    "        # Check time spent\n",
    "        e2 = cv2.getTickCount()\n",
    "        print('Cost time:',(e2 - e1)/cv2.getTickFrequency())\n",
    "        total_time += ((e2 - e1)/cv2.getTickFrequency())\n",
    "        \n",
    "        # Frame count \n",
    "        i += 1\n",
    "\n",
    "        # Quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Print Finished Hint Message\n",
    "    print(\"=== VOD_darkflow has finished. ===\")\n",
    "    print(\"Video was saved as:\", output_name)\n",
    "    \n",
    "    # Print Total Time Spent\n",
    "    print(\"=== Total Time Spent ===\")\n",
    "    print(total_time, ' secs')\n",
    "            \n",
    "    # Print Information Saved Hint Message\n",
    "    print(\"=== Detect Information saving... ===\")\n",
    "    to_json(dicto=total_info, json_file_name='total_info.json')\n",
    "    to_json(dicto=low_tag_dict, json_file_name='low_tag_dict.json')\n",
    "    to_json(dicto=high_tag_dict, json_file_name='high_tag_dict.json')\n",
    "    to_json(dicto=mid_tag_dict, json_file_name='mid_tag_dict.json')\n",
    "    to_json(dicto=total_tag_list, json_file_name='total_tag_list.json')\n",
    "    print(\"=== Detect Information was saved. ===\")\n",
    "    \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing ./cfg/yolo.cfg\n",
      "Parsing cfg/yolo.cfg\n",
      "Loading bin/yolo.weights ...\n",
      "Successfully identified 269862452 bytes\n",
      "Finished in 0.0512089729309082s\n",
      "Model has a coco model name, loading coco labels.\n",
      "\n",
      "Building net ...\n",
      "Source | Train? | Layer description                | Output size\n",
      "-------+--------+----------------------------------+---------------\n",
      "       |        | input                            | (?, 416, 416, 3)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 416, 416, 32)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 208, 208, 32)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 208, 208, 64)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 104, 104, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 104, 104, 64)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 104, 104, 128)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 52, 52, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 52, 52, 128)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 52, 52, 256)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 26, 26, 256)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | maxp 2x2p0_2                     | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1  +bnorm  leaky      | (?, 13, 13, 512)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | concat [16]                      | (?, 26, 26, 512)\n",
      " Load  |  Yep!  | local flatten 2x2                | (?, 13, 13, 2048)\n",
      " Load  |  Yep!  | concat [26, 24]                  | (?, 13, 13, 3072)\n",
      " Load  |  Yep!  | conv 3x3p1_1  +bnorm  leaky      | (?, 13, 13, 1024)\n",
      " Load  |  Yep!  | conv 1x1p0_1    linear           | (?, 13, 13, 425)\n",
      "-------+--------+----------------------------------+---------------\n",
      "GPU mode with 0.9 usage\n",
      "Finished in 4.659964084625244s\n",
      "\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 2.378567846\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.573971623\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.544687884\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.575505755\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.599522142\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.57285877\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.527684319\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.572310825\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.513587032\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.519597027\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.550057286\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.574942668\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.541863409\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.549826976\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.546050144\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.568557485\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.523103596\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.543062537\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.547467357\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.532044935\n",
      "=== Start Predicting with darkflow ===\n",
      "Cost time: 0.576455401\n",
      "=== VOD_darkflow has finished. ===\n",
      "Video was saved as: camVideo.avi\n",
      "=== Total Time Spent ===\n",
      "13.431725017000002  secs\n",
      "=== Detect Information saving... ===\n",
      "./demo_folder/obj_info/total_info.json\n",
      "./demo_folder/obj_info/low_tag_dict.json\n",
      "./demo_folder/obj_info/high_tag_dict.json\n",
      "./demo_folder/obj_info/mid_tag_dict.json\n",
      "./demo_folder/obj_info/total_tag_list.json\n",
      "=== Detect Information was saved. ===\n"
     ]
    }
   ],
   "source": [
    "# VOD_darkflow Example:\n",
    "VOD_darkflow(video_path=0, \n",
    "             video_fps=30, \n",
    "             output_name='DEMO.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Frame_caculator Func\n",
    "This is just for test. Cause it will play in real-time-counting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### This is just for test( Could do by mutiple fps with video_lengthSeconds)\n",
    "# def frame_caculator(video_path):\n",
    "#     total_frame = 0\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     while(True):\n",
    "#         try:\n",
    "#             ret, frame = cap.read()\n",
    "#             # cv2.imshow('frame',frame)\n",
    "#             if ret:\n",
    "#                 total_frame +=1\n",
    "#                 # Quit\n",
    "#                 if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#                     break\n",
    "#             else:\n",
    "#                 break\n",
    "#         except:\n",
    "#             break\n",
    "#     print('this is end', total_frame)\n",
    "#     # When everything done, release the capture\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n",
    "\n",
    "# Example frame_caculator\n",
    "# frame_caculator('./test.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Cut Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def video_cut(video_path, video_timeLength, video_fps, startTime_second, endTime_second, \n",
    "              output_fps, output_w, output_h, output_name='output.avi'):\n",
    "    \"\"\"\n",
    "        1. Input: video_path\n",
    "        2. Input: video_timeLength, the [total length of video] in seconds.\n",
    "        3. Input: video_fps, the [frames per second].\n",
    "        4. Input: startTime_second, is the [percentage of the spliting_start_time] of the video.\n",
    "        5. Input: endTime_second, is the [percentage of the spliting_end_time] of the video. \n",
    "        6. Input: set toe output video's [Output_fps, output_w, output_h].\n",
    "        7. Output: will be [.avi] format video with the [split part] of video.\n",
    "    \"\"\"\n",
    "    # Capture video\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_name, fourcc, output_fps, (output_w, output_h))\n",
    "    \n",
    "    # Set specific frame-range of video\n",
    "    frame_total = video_timeLength * video_fps   # 0 - frame_total\n",
    "    frame_start = startTime_second * video_fps   \n",
    "    frame_end = endTime_second * video_fps\n",
    "    print(frame_start, '--->', frame_end)\n",
    "    \n",
    "    # Check time \n",
    "    e1 = cv2.getTickCount()\n",
    "    \n",
    "    for i in range(frame_start, frame_end):\n",
    "        \n",
    "        # Set frame selection with frame place-percent(between 0.0-1.0)\n",
    "        cap.set(1, i)\n",
    "        \n",
    "        # Read and Save\n",
    "        ret, frame = cap.read()\n",
    "        print(i)\n",
    "        if ret:\n",
    "            \n",
    "            # Some tricks\n",
    "            kernel = np.ones((3,3),np.uint8)\n",
    "            frame = cv2.morphologyEx(frame, cv2.MORPH_OPEN, kernel)\n",
    "            \n",
    "            # Resize it \n",
    "            frame = cv2.resize(frame,(output_w, output_h), interpolation = cv2.INTER_CUBIC)\n",
    "            \n",
    "            # write the frame to the output\n",
    "            out.write(frame)\n",
    "            \n",
    "            # Show \n",
    "            cv2.imshow('frame',frame)\n",
    "            \n",
    "            # Exit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    # Check time spent\n",
    "    e2 = cv2.getTickCount()\n",
    "    print('Cost time:',(e2 - e1)/cv2.getTickFrequency())\n",
    "    \n",
    "    # Release everything if job is finished\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Video_cut Example \n",
    "# video_cut(video_path='./MrSmith.mp4',   # path to access video  \n",
    "#           video_timeLength=(5*60+8),    # Input video's property: total time-Length in second. \n",
    "#           video_fps=30,                 # Input video's property: video's frame per second.\n",
    "#           startTime_second=(0*60+22),   # cut_start_second:  ex: 20\n",
    "#           endTime_second=(0*60+40),     # cut_end_second:    ex: 30\n",
    "#           output_fps=30,                # Output video's property: video's frame per second. \n",
    "#           output_h=800,                 # Output video's property: video's height.\n",
    "#           output_w=600,                 # Output video's property: video's width. \n",
    "#           output_name='smith_18.avi')      # Output video's property: video's name. (format can't be changed here.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def videos_merge(video_path_list, output_fps, output_w, output_h, output_name = 'mergeee.avi'):\n",
    "    \"\"\"\n",
    "        1. Input: video_path_list\n",
    "        2. Input: set toe output video's [Output_fps, output_w, output_h].\n",
    "        3. Output: will be [.avi] format [merged] video.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out = cv2.VideoWriter(output_name, fourcc, output_fps, (output_w, output_h))\n",
    "\n",
    "    # Check time spent\n",
    "    e1 = cv2.getTickCount()\n",
    "    for video in video_path_list:\n",
    "        print('Start:', video)\n",
    "        \n",
    "        # Capture video\n",
    "        cap = cv2.VideoCapture(video)\n",
    "        while(True):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read() \n",
    "            if ret:\n",
    "                # write the frame to the output\n",
    "                out.write(frame)\n",
    "\n",
    "                # Show \n",
    "                cv2.imshow('frame',frame)\n",
    "\n",
    "                # Exit\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break \n",
    "        print('End:', video)\n",
    "        \n",
    "    # Check time spent\n",
    "    e2 = cv2.getTickCount()\n",
    "    print('Cost time:',(e2 - e1)/cv2.getTickFrequency())\n",
    "    \n",
    "    # When everything done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # videos_merge Example\n",
    "# video_path_list = ['./catdog_18.avi', './smith_18.avi', './conan_18.avi', './keny_181.avi', './keny_182.avi']\n",
    "# videos_merge(video_path_list=video_path_list, output_fps=30, output_h=800, output_w=600, output_name='mergeee.avi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def video_format_transfer(video_path, output_format='mp4', output_name='video_formatted', output_fps=30, output_w=800, output_h=600):\n",
    "    \n",
    "    # Define the codec and create VideoWriter object\n",
    "    if output_format == 'mp4':\n",
    "        fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    elif output_format == 'avi':\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    else:\n",
    "        fourcc = 0\n",
    "    \n",
    "    if fourcc:\n",
    "        out = cv2.VideoWriter(output_name, fourcc, output_fps, (output_w, output_h))\n",
    "\n",
    "        # Check time spent\n",
    "        e1 = cv2.getTickCount()\n",
    "        # Capture video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        while(True):\n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read() \n",
    "            if ret:\n",
    "                # Resize it \n",
    "                frame = cv2.resize(frame,(output_w, output_h), interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "                # write the frame to the output\n",
    "                out.write(frame)\n",
    "\n",
    "                # Show \n",
    "                cv2.imshow('frame',frame)\n",
    "\n",
    "                # Exit\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break \n",
    "\n",
    "        # Check time spent\n",
    "        e2 = cv2.getTickCount()\n",
    "        print('End:', video_path)\n",
    "        print('Cost time:',(e2 - e1)/cv2.getTickFrequency())\n",
    "\n",
    "        # When everything done, release the capture\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()       \n",
    "    else:\n",
    "        print('please Input the correct format: [\"MP4\" or \"AVI\"] ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# video_format_transfer Example :\n",
    "# video_format_transfer('./test.mpg', output_format='avi', output_name='video_formatted.mp4', output_fps=30, output_w=800, output_h=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tensorflow with gpu then [ \"gpu\": 0.7 will be working. ]\n",
    "# Reference: https://www.google.com.tw/search?q=darkflow+gpu&oq=darkflow+gpu&aqs=chrome..69i57.3855j0j7&sourceid=chrome&ie=UTF-8\n",
    "\n",
    "# >>> conda unistall tensorflow: 1.3.0-py35_0 conda-forge\n",
    "# >>> conda install tensorflow-gpu or pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CUDA with opencv? \n",
    "# https://jamesbowley.co.uk/buildcompile-opencv-v3-3-on-windows-with-cuda-8-0-and-intel-mkltbb/ 看不懂！？\n",
    "# https://www.scivision.co/anaconda-python-opencv3/ \n",
    "\n",
    "# print(cv2.getBuildInformation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# conda config --add channels conda-forge\n",
    "# conda install --use-local opencv\n",
    "# sudo apt-get install libavcodec-dev libavformat-dev libavdevice-dev\n",
    "# sudo apt-get install pkg-config\n",
    "# sudo apt-get install libgtk2.0-dev\n",
    "\n",
    "\n",
    "\n",
    "# problem issue # opencv Unable to stop the stream: Inappropriate ioctl for device\n",
    "# https://stackoverflow.com/questions/42562876/opencv3-error-unable-to-stop-the-stream-inappropriate-ioctl-for-device\n",
    "# https://stackoverflow.com/questions/41200201/opencv-unable-to-stop-the-stream-inappropriate-ioctl-for-device\n",
    "\n",
    "\n",
    "# OR JUST INSTALL cv2 version: 3.3.0\n",
    "# 3.3 problem # scn == 3 || scn == 4 in function cvtColor\n",
    "# https://github.com/HackerHouseYT/AI-Smart-Mirror/issues/36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
